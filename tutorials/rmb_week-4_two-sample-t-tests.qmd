---
engine: knitr
---

```{r}
#| echo: false
library(webexercises)
```

# Week 4 : Two-Sample t-tests {.unnumbered}

This week we will explore how to use Jamovi to test hypotheses about a dataset using t-tests. We will touch on some revision from previous weeks so please do jump back to past computer practicals for revision if required

|  ![](../images/logos/rm-logo_quantitative-methods.png){width=50px}  | Quantitative Methods                                    |
|-----|:-------------------------------------------|
|            | Independent samples t-tests                            |
|            | Paired samples t-tests                           |
|            | Assumptions of parametric tests                           |

: Learning objectives for this session

|    ![](../images/logos/rm-logo_data-skills.png){width=50px}      | Data Skills                                               |
|-----|:-------------------------------------------|
|          | Computing a new variable from existing data    |
|          | Computing checks for normality and homogeneity of variance                  |


|      ![](../images/logos/rm-logo_open-science.png){width=50px}      | Open Science                                               |
|-----|:-------------------------------------------|
|          | Exploring and understanding new datasets       |

## 1. The Dataset {.unnumbered}

We'll be working with the dataset we collected after the break during the lecture in Week 3. This is a partial replication of a study published in the journal Psychological Science [@Miller2024_AIHyperrealism]. The original paper found the following results summarised in the abstract.

>Recent evidence shows that AI-generated faces are now indistinguishable from human faces. However, algorithms are trained disproportionately on White faces, and thus White AI faces may appear especially realistic. In Experiment 1 (N = 124 adults), alongside our reanalysis of previously published data, we showed that White AI faces are judged as human more often than actual human faces—a phenomenon we term AI hyperrealism. Paradoxically, people who made the most errors in this task were the most confident (a Dunning-Kruger effect). In Experiment 2 (N = 610 adults), we used face-space theory and participant qualitative reports to identify key facial attributes that distinguish AI from human faces but were misinterpreted by participants, leading to AI hyperrealism. However, the attributes permitted high accuracy using machine learning. These findings illustrate how psychological theory can inform understanding of AI outputs and provide direction for debiasing AI algorithms, thereby promoting the ethical use of AI.

We ran a quiz that students in the lecture could join on their phones/laptops. There were two parts to the quiz:

The faces section included 12 faces that were either photographs or real people or AI generated images of people. The stimuli were taked from the materials released by [@Miller2024_AIHyperrealism] on the [Open Science Framework](https://osf.io/ru36d/). Responses were either 'Real person' or 'AI generated'.

![Stimuli from: Miller, E. J., Steward, B. A., Witkower, Z., Sutherland, C. A. M., Krumhuber, E. G., & Dawel, A. (2023). AI Hyperrealism: Why AI Faces Are Perceived as More Real Than Human Ones. Psychological Science, 34(12), 1390–1403. https://doi.org/10.1177/09567976231207095
](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img0-2026.png){.lightbox width="600px"}


The confidence section asked participants to rate their confidence in their ability to do the following three things.

 - Distinguish real photos of people from AI generated images  (Experimental condition)
 - Distinguish photos of happy people from photos of sad people (Emotional control condition)
 - Distinguish photos of people you used to know in primary school from strangers (Memory control condition)

 Scores were recorded on a scale from 1 (Completely confidence) to 10 (Not at all confident). The confidence section was repeated before and after the faces section to see if participants confidence changed as a result of doing the AI faces task

## 2. The Challenge {.unnumbered}

This week we will use both one sample and two sample t-tests to explore the following hypotheses.

- People are able to distinguish AI generated faces from real photos of humans.
- Confident people are better at distinguishing AI faces from real faces.
- People's confidence in distinguishing AI generated faces will reduce after performing the task, but their confidence about emotion perception and memory will not change.

::: {.callout-note appearance="simple"}
# Key step

Take a moment to think about these hypotheses. Which statistical test is most appropriate for each? Do they call for a one-tailed or a two-tailed test?

:::

## 2. Exploring the data {.unnumbered}

It is critical to take some time to understand the data we work with before running critical hypothesis tests. Here we'll take a look through the dataset to understand what information is present and if we're happy to proceed with the analysis. This is similar to what we did in week 1 - you can refer back to the week 1 materials for additional guidance if you need it.

::: {.callout-note appearance="simple"}
# Key step

Before going any further, the data file `rmb-week-3_lecture-quiz-data_ai-faces-2026.csv` into a new Jamovi session.

:::

Take a read through the data columns. We have 26 in total with the following information.


| Column Names             |  Description              |
|--------------------------|----------------------------------------------------------|
| `First Name`                |  Participant ID - always 'Anonymous'               |
| `DataUse`                | Participant response to data re-use question               |
| `AIConfidenceBefore`     | Confidence in distinguishing AI faces from real BEFORE the task : 1 (Completely confident) to 10 (Not at all confident)               |
| `EmoConfidenceBefore`    | Confidence in distinguishing happy from sad faces BEFORE the task (Emotional control) : 1 (Completely confidence) to 10 (Not at all confident)           |
| `MemoryConfidenceBefore` | Confidence in recognising a face from a long time ago BEFORE the task (Memory control) : 1 (Completely confidence) to 10 (Not at all confident)             |
| `Face1_Real`             | Result for face (1 is correct response, 0 is incorrect)              |
| `Face2_Real`             | Result for face (1 is correct response, 0 is incorrect)              |
| `Face3_AI`               | Result for face (1 is correct response, 0 is incorrect)              |
| `Face4_AI`               | Result for face (1 is correct response, 0 is incorrect)              |
| `Face5_AI`               | Result for face (1 is correct response, 0 is incorrect)              |
| `Face6_AI`               | Result for face (1 is correct response, 0 is incorrect)              |
| `Face7_Real`             | Result for face (1 is correct response, 0 is incorrect)              |
| `Face8_Real`             | Result for face (1 is correct response, 0 is incorrect)              |
| `Face9_Real`             | Result for face (1 is correct response, 0 is incorrect)              |
| `Face10_Real`            | Result for face (1 is correct response, 0 is incorrect)              |
| `Face11_AI`              | Result for face (1 is correct response, 0 is incorrect)              |
| `Face12_AI`              | Result for face (1 is correct response, 0 is incorrect)              |
| `Quiz1`                  | Response for revision quiz question              |
| `Quiz2`                  | Response for revision quiz question              |
| `Quiz3`                  | Response for revision quiz question              |
| `AIConfidenceAfter`      | Confidence in distinguishing AI faces from real AFTER the task               |
| `EmoConfidenceAfter`     | Confidence in distinguishing happy from sad faces AFTER the task (Emotional control)           |
| `MemoryConfidenceAfter`  | Confidence in recognising a face from a long time ago AFTER the task (Memory control)              |


Work through the following questions, try to get an answer yourself before clicking to see the result. Data exploration is a critical skill that you'll need whenever looking a new data throughout your degree.

:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Fill in the gaps to check your understanding of this dataset.

A total of `r fitb(172)` participants are included in the dataset, of these `r fitb(0)` indicated that they did not want their data to be included in the shared dataset.

We would expect `r fitb(50)`% accuracy if the participants answered randomly on the the Real or AI face discrimination.

:::
::::


The columns containing the responses for each face have a `0` when the participant was incorrect and a `1` when the participant was correct for that face.

::: {.callout-note appearance="simple"}
# Key step

Compute desriptive statistics for all 12 faces and look at the 'Mean'.

This indicates the proportion of participants that correctly identified whether the fact was of a real person or generated by AI. This can be converted to a percentage by multiplying it by 100.

:::

You can use Descriptive Statistics to answer the following questions.


:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Fill in the gaps to check your understanding of this dataset.

The most accurately identified image was face `r fitb(10)`, which was correctly identified as `r mcq(c(answer = 'A real person', 'AI'))` `r fitb(96.8)`% of the time. A total of `r fitb(18)` participants did NOT give a response for this face.

The least accurately identified image was face `r fitb(8)`, which was correctly identified as `r mcq(c(answer = 'A real person', 'AI'))` `r fitb(22)`% of the time. A total of `r fitb(31)` participants did NOT give a response for this face.

:::
::::

::: {.callout-note appearance="simple"}
# Key step

Open a new desriptive statistics tab and compute descriptives for the six confidence questions (3 were before the faces, and 3 were afterwards).

The questions asked how confidence you were that you can do the following:

1. Distinguish real photos of people from AI generated images (AI)
2. Distinguish photos of happy people from sad people (Emotion)
3. Distinguish phtotos of people you used to know in primary school from strangers (Memory)

The confidence scale ranges from 1 to 9, in which 1 means 'Completely Confident' and 9 means 'Not at all confident'.

Take a moment to get familiar with the outputs.

:::

:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Use the descriptive statistics on the confidence questions to fill in the gaps, you may have to compute some additional descriptive statistics along the way.

Before the face task, participants were most confident in their ability to distinguish `r mcq(c('real photos of people from AI generated images', answer = 'photos of happy people from photos of sad people', 'photos of people you used to know in primary school from strangers'))` with an average confidence of `r fitb(2.95)` and 95% confidence intervals ranging from a lower bound of `r fitb(2.58)` to an upper bound of `r fitb(3.31)`

Participants were least confident in their ability to distinguish `r mcq(c(answer = 'real photos of people from AI generated images', 'photos of happy people from photos of sad people', 'photos of people you used to know in primary school from strangers'))` with an average confidence of `r fitb(4.40)` and 95% confidence intervals ranging from a lower bound of `r fitb(4.14)` to an upper bound of `r fitb(4.66)`

Comparing confidence before and after the fact task, confidence in indentifying AI faces from real faces `r mcq(c(answer = 'decreased', 'increased'))` from `r fitb(4.40)` before to `r fitb(6.38)` afterwards.

Confidence in indentifying happy faces from sad faces `r mcq(c('decreased', answer = 'increased'))` from `r fitb(2.95)` before to `r fitb(2.85)` afterwards.

Confidence in indentifying people you used to know in primary school from strangers  `r mcq(c(answer = 'decreased', 'increased'))` from `r fitb(3.51)` before to `r fitb(3.63)` afterwards.


:::
::::



## 3. Computing overall accuracy

The descriptive statistics gave us a good overview of the dataset and we can start working towards testing our hypotheses.

One critical piece of information is missing though! we have accuracy for each individual face but not an overall score for each participant. We'll need to compute this new variable ourselves from the average accuracy of all twelve faces.


::: callout-tip
## Data Skills - computing a variable from other columns

We can define our own variables in Jamovi using the 'Compute' function in the 'Variables' or the 'Data' tabs. Open a new Transformed variable.

This will open a menu with an option to give the new variable an name and description. Name the variable `PropFacesCorrect` to indicate that it contatins the proportion of faces that the participant responded correctly on. You can add a description if you like though this is optional.

The variable is defined within the formula box below the name definitions. We want to compute the average accuracy across all 12 faces so we can add the formula to compute that into the box.

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img3-2026.png){.lightbox width="600px"}

We can use the `MEAN` function to do this, you can see a list of all available functions by looking in the $f_x$ drop-down menu. You can click a function to see what it does and double click it to add it to the computed variable.

`MEAN` will add all the columns together and divide the result by 12 (the total number of faces). Make sure that all the columns are grouped by parentheses! otherwise Jamovi will only divide the final included in a comma separated list within the parentheses.

The formula should look something like this, I've removed some faces to simplify the visualisation. You should include them all.

```
= MEAN(Face1_Real, Face2_Real, ... , Face11_AI, Face12_AI)
```

Once this is complete, you should be able to find your new column of values.

:::

Now, let's take a look at our new variable.

::: {.callout-note appearance="simple"}
# Key step

Compute desriptive statistics for the new `PropFacesCorrect` variable.

Take a moment to explore and understand the results.

:::


:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Use the descriptive statistics on the `PropFacesCorrect` to fill in the gaps, you may have to compute some additional descriptive statistics along the way.

A total of `r fitb(61)` participants responded to all 12 faces, with `r fitb(111)` people missing an answer on at least one face

(Note from Andrew: I'll give more than 10 seconds per face next year!)

The least accurate participant got a proportion of `r fitb(0.25)` correct, this corresponds to `r fitb(3)` correct responses out of a possible 12.

The most accurate participant got a proportion of `r fitb(0.917)` correct, this corresponds to `r fitb(11)` correct responses out of a possible 12.

The group average was a proportion of `r fitb(0.527)` correct responses with a 95% confidence interval between a lower bound of `r fitb(0.490)` and an upper bound of `r fitb(0.564)`.

## Hint

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img3b-2026.png){.lightbox width="350px"}


:::
::::


## 4. Hypothesis 1 - People are able to distinguish AI generated faces from real photos of humans {.unnumbered}

Ok, we're ready to test the first hypothesis. Use the information you know about the dataset and try to find an answer!

::: {.callout-note appearance="simple"}
# Key step

Run a one sample t-test testing whether the proportion of correctly identified faces was above chance level for the group, include some descriptive statistics to help you interpret the result.


:::


<!--# #############################################  -->

:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Using your results, address the following hypothesis:

> People are able to distinguish AI generated faces from real photos of humans

What sort of hypothesis is this and what is the most approprate statistical test?

Compute the statistics, do the data support the experimental or the null hypothesis?

Once you have finished, complete this writing to report the results as if it were in a paper or report.

A one sample t-test comparing the group average proportion of correctly identified faces (M = `r fitb(0.527)`, SD=`r fitb(0.144)`) to chance level (proportion correct = `r fitb(0.5)`) showed a significant effect, t(`r fitb(60)`) = `r fitb(1.48)`, p=`r fitb(0.144)`. We can conclude that participants in the experiment were `r mcq(c('able', answer = 'not able'))` to distinguish AI generated faces from real faces.

## Hint

The results for your t-test should look like this:

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img5-2026.png){.lightbox width="400px"}

:::
::::


## 5. Hypothesis 2 - Confident people are better at distinguishing AI faces from real faces. {.unnumbered}

Now the second hypothesis. We don't have everything we need to test this hypothesis yet. We'll need some way to split our participants into two groups - one with high confidence in AI face detection and one with low confidence. Time to compute another variable.

<!--# #############################################  -->

:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Compute a new variable named `ConfidentBefore` that separates the groups based on the median AI face detection confidence before the task.

## Hint

You'll need the median value for `AIConfidenceBefore` - you can compute this from descriptive statistics.

The computed variable will need some logical condition (using operators like '>', '<' or '==') that separates participants with confidence above and below the median.

## Solution

The median value for `AIConfidenceBefore` is `4`, so our computed variable definition will look like this.

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img6.png){.lightbox width="600px"}

The values in `ConfidentBefore` will now be 'True' for people with  high confidence (above 4) and 'False' for people with low confidence (below 4). It doesn't matter if you've done this the other way around - the tests will still work but the results will be flipped in the other direction (multiplied by -1)

:::
::::

With our new variable, we have what we need to run an independent samples t-test. This is very straightforward following the analyses we've run previously in the module.

::: {.callout-note appearance="simple"}
# Key step

Open the 'Independent Sample t-test' menu under 't-tests'. To run the analysis, drag `PropFacesCorrect` across as our dependent variable and our new `ConfidentBefore` variable as the grouping variable. The results should appear on the right automatically.

Add all three variants of the t-test:

- Students t-test
- Welch's t-test
- Mann-Whitney U test (non-parametric alternative)

add the following options:

- Descriptives
- Homogeneity Test
- Normality Test

:::

Let's think through the results

::: {.callout-caution icon="false" collapse="true"}
## <i class="bi bi-question-lg"></i> Data Skills - are the data normally distributed?

The Shairo-Wilk statistic is significant, indicating that the data are **not** likely to be normally distributed

:::

::: {.callout-caution icon="false" collapse="true"}
## <i class="bi bi-question-lg"></i> Data Skills - do we have homogeneity of variance?

Levene's statistic is not significant, indicating that the variance of the two groups is comparable. We can confirm this by looking at the standard deviations in the descriptives table. 0.140 and 0.149 are fairly similar so the test report makes intuitive sense.

:::

::: {.callout-caution icon="false" collapse="true"}
## <i class="bi bi-question-lg"></i> Data Skills - which test should we report? Student's, Welch's or Mann-Whitney U?

We can assume homogeneity of variance but we cannot assume normality, we should proceed with the non-parametric alternative test the **Mann-Whitney U**.

:::


:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Let's interpret the results. Fill in the blanks with results for the correct statistical test (see the last data-skills drop down question!).

Report the medians if we're using the Mann-Whitney U test.

| Statistic        | Value |
| ----------- | ----------- |
| Statistical Test | `r mcq(c("Student's t", "Welch's t", answer = 'Mann-Whitney U'))`
| Test statistic (`t` or `U`)      | `r fitb(374)`       |
| Degrees of freedom (Ignore for Mann-Whitney U)   | `r fitb(-1)`     |
| p-value   | `r fitb(0.377)`     |
| Mean for high confidence (or median)   | `r fitb(0.5)`     |
| Mean for low confidence (or median)   | `r fitb(0.5)`     |

The results mean we should `r mcq(c("Reject", answer = 'Accept'))` the null hypothesis that people's confidence does not relate to their ability to distinguish AI generated faces from the faces of real people.


## Hint

Your results table should look like this:

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img7-2026.png){.lightbox width="600px"}


:::
::::



## 6. Hypothesis 3 - People’s confidence in their ability to distinguish AI generated faces will reduce after performing the task  {.unnumbered}

Next we want to explore whether performing the face decision task changes peoples confidences in their abililty to detect AI generated faces. Remember that all participants categorised 12 faces with immediate correct/incorrect feedback and made confidence ratings at the start and end of the task.

::: {.callout-note appearance="simple"}
# Key step

Open the 'Paired Sample t-test' menu under 't-tests'. To run the analysis, drag `AIConfidenceBefore` and `AIConfidenceAfter` across as our pair of dependent variables. This is the format for running paired samples t-tests, the rest of the options should be familiar from our previous analyses.

Once you have computed the core test, do the same for the `EmoConfidence` and `MemoryConfidence`, and add the following options:

- Descriptives
- Normality Test
- Wilcoxon Rank Test (non-parametric alternative)

The results should appear on the right automatically.

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img8-2026.png){.lightbox}

Take a moment to read through and understand the results.

:::

Let's think through what this all means...


:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Use your results to fill in the gaps in these results.

A paired samples t-test showed `r mcq(c("no significant", answer = 'a significant'))` difference in participants confidence in their ability to distinguish AI faces from real faces before (M=`r fitb(4.29)`, SD=`r fitb(1.72)`) and after (M=`r fitb(6.42)`, SD=`r fitb(2.23)`) the face perception task. t(`r fitb(114)`) = `r fitb(-8.695)`, p=`r fitb(0.001)`. Participant's confidence was `r mcq(c(answer = "significantly reduced", "the same", 'significantly increased'))` after completing the face task.


The Shapio-Wilk statistic indicated that the emotional perception scores violated the assumption of normality (W=`r fitb(0.665)`, p=M=`r fitb(0.001)`). A Wilcoxon Rank test showed  `r mcq(c(answer="no significant", 'a significant'))` difference in participant's confidence in their ability to distinguish happy faces from sad faces before (Median=`r fitb(2)`) and after (Median=`r fitb(3)`) the task.


The Shapio-Wilk statistic indicated that the memory scores violated the assumption of normality (W=`r fitb(0.752)`, p=M=`r fitb(0.001)`). A Wilcoxon Rank test showed  `r mcq(c(answer="no significant", 'a significant'))` difference in participant's confidence in their ability to distinguish people you used to know in primary school from strangers before (Median=`r fitb(3)`) and after (Median=`r fitb(3)`) the task.

:::
::::


<!--# #############################################

## 7. Bonus Hypothesis! People are more accurate at identifying photos of real people compared to AI generated photos.

Let's use our new skills from this practical to answer one last question.


:::: callout-tip
## Check Your Understanding

::: panel-tabset
## Question

Use a t-test to test this hypothesis:

> People are more accurate at identifying photos of real people compared to AI generated photos

You'll several of the skills from this session to answer the question... think through what sort of variables you'll need and what sort of test you'll need.

## Hint

We need 2 new variables to answer this question. We have already computed `PropCorrectFaces` in an earlier section, but we now need to make separate versions of this for AI faces and real faces...

The variable transforms will look something like this:

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img9a.png){width="600px"}
![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img9b.png){width="600px"}

What sort of t-test will you need?

## Solution

We need to compute a paired samples t-test to answer the question as each participant contributes to both the AI face and real face conditions. Compute the test along with some descriptive statistics, we can report the test as follows

> A paired samples t-test showed a significant difference in the correct identification of AI faces (M=0.702, SD=0.198) compared to real faces (M=0.566, SD=0.229). t(85) = -4.60, p<0.001. AI faces were identified more accurately than real faces.

![](../images/rmb-week-4_computer-practical/rmb-week-4_computer-practical_img10.png){width="600px"}


:::
::::
-->

## 8. Summary

We've computed a range of tests to statistically assess our hypotheses today! One experiment can often yield enough data to run a wide range of analyses. It is always a good idea to start with your hypotheses and predictions to break the analysis down into manageable chunks.



## References {.unnumbered}

